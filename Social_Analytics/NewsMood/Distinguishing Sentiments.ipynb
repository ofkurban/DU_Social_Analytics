{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NewsMood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import tweepy\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "#from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = \"XXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "consumer_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "access_token = \"xxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "access_token_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "# Select News Sources (Twitter Accounts)\n",
    "news_source = [\"FoxNews\",\"CNN\",\"BBCWorld\",\"CBSNews\",\"nytimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User': '@BBC', 'Date': 'Wed Dec 13 20:21:18 +0000 2017', 'Compound': [0.0073812500000000041], 'Positive': 0.030343750000000003, 'Neutral': 0.030031249999999999, 'Negative': 0.93962500000000004, 'Tweet Count': 320}\n",
      "\n",
      "{'User': '@CBSNews', 'Date': 'Wed Dec 13 20:41:15 +0000 2017', 'Compound': [0.072343893805309742], 'Positive': 0.10447787610619469, 'Neutral': 0.077752212389380529, 'Negative': 0.81778761061946892, 'Tweet Count': 565}\n",
      "\n",
      "{'User': '@CNN', 'Date': 'Wed Dec 13 20:46:57 +0000 2017', 'Compound': [-0.018937049742710117], 'Positive': 0.061030874785591771, 'Neutral': 0.074048027444253858, 'Negative': 0.86487478559176667, 'Tweet Count': 583}\n",
      "\n",
      "{'User': '@FoxNews', 'Date': 'Wed Dec 13 20:47:13 +0000 2017', 'Compound': [0.019689386792452825], 'Positive': 0.10115094339622643, 'Neutral': 0.090462264150943383, 'Negative': 0.80836320754716973, 'Tweet Count': 424}\n",
      "\n",
      "{'User': '@nytimes', 'Date': 'Wed Dec 13 20:46:25 +0000 2017', 'Compound': [-0.032855733333333338], 'Positive': 0.11300533333333336, 'Neutral': 0.13307733333333333, 'Negative': 0.75399733333333341, 'Tweet Count': 375}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Target Search Term\n",
    "target_terms = (\"@BBC\",\"@CBSNews\",\"@CNN\",\"@FoxNews\", \"@nytimes\")\n",
    "\n",
    "# \"Real Person\" Filters\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\"\n",
    "\n",
    "# Array to hold sentiment\n",
    "sentiment_array = []\n",
    "\n",
    "# Variable for holding the oldest tweet\n",
    "oldest_tweet = \"\"\n",
    "\n",
    "# Loop through all target users\n",
    "for target in target_terms:\n",
    "\n",
    "    # Variables for holding sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "\n",
    "    # Loop through 10 times (total of 1000 tweets)\n",
    "    for x in range(10):\n",
    "\n",
    "        # Run search around each tweet\n",
    "        public_tweets = api.search(target, count=100, result_type=\"recent\")\n",
    "\n",
    "        # Loop through all tweets\n",
    "        for tweet in public_tweets[\"statuses\"]:\n",
    "\n",
    "            # Use filters to check if user meets conditions\n",
    "            if (tweet[\"user\"][\"followers_count\"] < max_followers and\n",
    "                tweet[\"user\"][\"statuses_count\"] > min_tweets and\n",
    "                tweet[\"user\"][\"statuses_count\"] < max_tweets and\n",
    "                tweet[\"user\"][\"friends_count\"] < max_following and\n",
    "                    tweet[\"user\"][\"lang\"] == lang):\n",
    "\n",
    "                # Run Vader Analysis on each tweet\n",
    "                compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "                pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "                neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "                neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "                # Add each value to the appropriate array\n",
    "                compound_list.append(compound)\n",
    "                positive_list.append(pos)\n",
    "                negative_list.append(neg)\n",
    "                neutral_list.append(neu)\n",
    "\n",
    "    # Store the Average Sentiments\n",
    "    sentiment = {\"User\": target,\n",
    "                 \"Date\": tweet[\"created_at\"],\n",
    "                 \"Compound\": [np.mean(compound_list)],\n",
    "                 \"Positive\": np.mean(positive_list),\n",
    "                 \"Neutral\": np.mean(negative_list),\n",
    "                 \"Negative\": np.mean(neutral_list),\n",
    "                 \"Tweet Count\": len(compound_list)}\n",
    "\n",
    "    # Print the Sentiments\n",
    "    print(sentiment)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment to DataFrame\n",
    "#twittersentiment = pd.DataFrame.from_dict(sentiment)\n",
    "#twittersentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export the new CSV\n",
    "#twittersentiment.to_csv(\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "#plt.plot(np.arange(len(sentiments_pd[\"Compound\"])),\n",
    "#          sentiments_pd[\"Compound\"], marker=\"o\", linewidth=0.5,\n",
    "#          alpha=0.8)\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "#plt.title(\"Sentiment Analysis of Tweets (%s) for %s\" % (time.strftime(\"%x\"), target_terms))\n",
    "#plt.ylabel(\"Tweet Polarity\")\n",
    "#plt.xlabel(\"Tweets Ago\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Sentiment Bar Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average all polarities by news source\n",
    "#tweet_df_polarity = tweet_df.groupby([\"tweet_source\"]).mean()[\"tweet_vader_score\"]\n",
    "\n",
    "#View the polarities\n",
    "#pd.DataFrame(tweet_df_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store all polarities in a tuple \n",
    "#tweets_polarity = (tweet_df_polarity[\"BBC News (World)\"],\n",
    "#                        tweet_df_polarity[\"CBS News\"],\n",
    "#                        tweet_df_polarity[\"CNN\"],\n",
    "#                        tweet_df_polarity[\"Fox News\"],\n",
    "#                        tweet_df_polarity[\"The New York Times\"])\n",
    "\n",
    "#Generate bars for each news source\n",
    "#fig, ax = plt.subplots()\n",
    "#ind = np.arange(len(tweets_polarity))\n",
    "#width = 1\n",
    "#rect1 = ax.bar(ind[0], tweets_polarity[0], width, color=\"skyblue\")\n",
    "#rect2 = ax.bar(ind[1], tweets_polarity[1], width, color=\"skyblue\")\n",
    "#rect3 = ax.bar(ind[2], tweets_polarity[2], width, color=\"skyblue\")\n",
    "#rect4 = ax.bar(ind[3], tweets_polarity[3], width, color=\"skyblue\")\n",
    "#rect5 = ax.bar(ind[4], tweets_polarity[4], width, color=\"skyblue\")\n",
    "\n",
    "#Generate labels for each news source\n",
    "#def autolabelpos(rects):\n",
    "#    # attach some text labels\n",
    "#    for rect in rects:\n",
    "#        height = rect.get_height()\n",
    "#        ax.text(rect.get_x() + rect.get_width()/2., 1*height, '+%.2f' % float(height)),ha='center', va='bottom'\n",
    "#def autolabelneg(rects):\n",
    "    # attach some text labels\n",
    "#    for rect in rects:\n",
    "#        height = rect.get_height()\n",
    "#        ax.text(rect.get_x() + rect.get_width()/2., -1*height-0.015,\n",
    "#                '-%.2f' % float(height),\n",
    "#                ha='center', va='bottom')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
